#!/usr/bin/env python
"""
æ¶ˆèå®éªŒç»“æœæ±‡æ€»è„šæœ¬
ä»å„ä¸ªå®éªŒç›®å½•ä¸­æå–ç»“æœå¹¶ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
"""

import os
import json
import argparse
import pandas as pd
import numpy as np
from pathlib import Path


def extract_best_metrics(exp_dir):
    """ä»å®éªŒç›®å½•ä¸­æå–æœ€ä½³æŒ‡æ ‡"""
    history_val_file = os.path.join(exp_dir, 'history_val.json')

    if not os.path.exists(history_val_file):
        return None

    with open(history_val_file, 'r') as f:
        history = json.load(f)

    # æ£€æµ‹ä»»åŠ¡ç±»å‹
    metrics_available = list(history.keys())
    is_classification = 'accuracy' in metrics_available

    results = {
        'exp_dir': os.path.basename(exp_dir),
    }

    if is_classification:
        # åˆ†ç±»ä»»åŠ¡
        results['best_val_accuracy'] = max(history['accuracy']) if 'accuracy' in history else None
        results['best_val_precision'] = max(history['precision']) if 'precision' in history else None
        results['best_val_recall'] = max(history['recall']) if 'recall' in history else None
        results['best_val_loss'] = min(history['loss']) if 'loss' in history else None
        results['final_val_accuracy'] = history['accuracy'][-1] if 'accuracy' in history else None
    else:
        # å›å½’ä»»åŠ¡
        results['best_val_mae'] = min(history['mae']) if 'mae' in history else None
        results['best_val_loss'] = min(history['loss']) if 'loss' in history else None
        results['final_val_mae'] = history['mae'][-1] if 'mae' in history else None
        results['final_val_loss'] = history['loss'][-1] if 'loss' in history else None

    # è®­ç»ƒè½®æ¬¡
    results['total_epochs'] = len(history['loss']) if 'loss' in history else None

    return results


def extract_test_metrics(exp_dir):
    """ä»é¢„æµ‹æ–‡ä»¶ä¸­æå–æµ‹è¯•é›†æŒ‡æ ‡"""
    # å°è¯•ä¸‰ä¸ªç‰ˆæœ¬çš„é¢„æµ‹æ–‡ä»¶
    pred_files = [
        'predictions_best_val_model_test.csv',
        'predictions_best_test_model_test.csv',
        'prediction_results_test_set.csv'
    ]

    for pred_file in pred_files:
        pred_path = os.path.join(exp_dir, pred_file)
        if os.path.exists(pred_path):
            df = pd.read_csv(pred_path)

            # ç§»é™¤åˆ—åä¸­çš„ç©ºæ ¼
            df.columns = df.columns.str.strip()

            # æ£€æµ‹ä»»åŠ¡ç±»å‹
            unique_targets = df['target'].nunique()
            is_classification = unique_targets <= 10 and set(df['target'].unique()).issubset({0, 1})

            if is_classification:
                # åˆ†ç±»ä»»åŠ¡
                from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
                y_true = df['target'].values.astype(int)
                y_pred = (df['prediction'].values > 0.5).astype(int)

                return {
                    'test_accuracy': accuracy_score(y_true, y_pred),
                    'test_precision': precision_score(y_true, y_pred, zero_division=0),
                    'test_recall': recall_score(y_true, y_pred, zero_division=0),
                    'test_f1': f1_score(y_true, y_pred, zero_division=0),
                }
            else:
                # å›å½’ä»»åŠ¡
                from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
                y_true = df['target'].values
                y_pred = df['prediction'].values

                return {
                    'test_mae': mean_absolute_error(y_true, y_pred),
                    'test_rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
                    'test_r2': r2_score(y_true, y_pred),
                }

    return {}


def summarize_ablation_experiments(ablation_dir):
    """æ±‡æ€»æ‰€æœ‰æ¶ˆèå®éªŒç»“æœ"""

    print("\n" + "="*80)
    print("ğŸ“Š æ¶ˆèå®éªŒç»“æœæ±‡æ€»")
    print("="*80)

    # å®éªŒé…ç½®æ˜ å°„
    exp_configs = {
        'exp1_text_concat_baseline': {
            'name': 'Exp-1: Text Simple Concat (Baseline)',
            'cross_modal': 'âŒ',
            'middle_fusion': 'âŒ',
            'fine_grained': 'âŒ',
        },
        'exp2_late_fusion': {
            'name': 'Exp-2: +Late Fusion',
            'cross_modal': 'âœ…',
            'middle_fusion': 'âŒ',
            'fine_grained': 'âŒ',
        },
        'exp3_middle_fusion': {
            'name': 'Exp-3: +Middle Fusion (åˆ›æ–°1)',
            'cross_modal': 'âœ…',
            'middle_fusion': 'âœ…',
            'fine_grained': 'âŒ',
        },
        'exp4_fine_grained': {
            'name': 'Exp-4: +Fine-Grained (åˆ›æ–°2)',
            'cross_modal': 'âœ…',
            'middle_fusion': 'âŒ',
            'fine_grained': 'âœ…',
        },
        'exp5_full_model': {
            'name': 'Exp-5: Full Model',
            'cross_modal': 'âœ…',
            'middle_fusion': 'âœ…',
            'fine_grained': 'âœ…',
        },
    }

    # æ”¶é›†æ‰€æœ‰å®éªŒç»“æœ
    all_results = []

    for exp_id, config in exp_configs.items():
        exp_dir = os.path.join(ablation_dir, exp_id)

        if not os.path.exists(exp_dir):
            print(f"âš ï¸  æœªæ‰¾åˆ°å®éªŒç›®å½•: {exp_dir}")
            continue

        print(f"\nå¤„ç†: {config['name']}...")

        # æå–éªŒè¯é›†æŒ‡æ ‡
        val_metrics = extract_best_metrics(exp_dir)
        if val_metrics is None:
            print(f"  âŒ æœªæ‰¾åˆ°éªŒè¯é›†ç»“æœ")
            continue

        # æå–æµ‹è¯•é›†æŒ‡æ ‡
        test_metrics = extract_test_metrics(exp_dir)

        # åˆå¹¶ç»“æœ
        result = {
            'Experiment': config['name'],
            'Cross-Modal': config['cross_modal'],
            'Middle Fusion': config['middle_fusion'],
            'Fine-Grained': config['fine_grained'],
        }
        result.update(val_metrics)
        result.update(test_metrics)

        all_results.append(result)
        print(f"  âœ… æˆåŠŸæå–ç»“æœ")

    if not all_results:
        print("\nâŒ æœªæ‰¾åˆ°ä»»ä½•å®éªŒç»“æœ")
        return

    # åˆ›å»ºDataFrame
    df = pd.DataFrame(all_results)

    # ä¿å­˜åˆ°CSV
    output_csv = os.path.join(ablation_dir, 'ablation_summary.csv')
    df.to_csv(output_csv, index=False)
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_csv}")

    # æ‰“å°æ±‡æ€»è¡¨æ ¼
    print("\n" + "="*80)
    print("ğŸ“Š éªŒè¯é›†æœ€ä½³ç»“æœå¯¹æ¯”")
    print("="*80)

    # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
    if 'best_val_mae' in df.columns:
        # å›å½’ä»»åŠ¡
        display_cols = ['Experiment', 'Cross-Modal', 'Middle Fusion', 'Fine-Grained',
                       'best_val_mae', 'test_mae', 'test_r2']
        if all(col in df.columns for col in display_cols):
            print(df[display_cols].to_string(index=False))
    elif 'best_val_accuracy' in df.columns:
        # åˆ†ç±»ä»»åŠ¡
        display_cols = ['Experiment', 'Cross-Modal', 'Middle Fusion', 'Fine-Grained',
                       'best_val_accuracy', 'test_accuracy', 'test_f1']
        if all(col in df.columns for col in display_cols):
            print(df[display_cols].to_string(index=False))

    # è®¡ç®—ç›¸å¯¹æå‡
    print("\n" + "="*80)
    print("ğŸ“ˆ ç›¸å¯¹æ€§èƒ½æå‡åˆ†æ")
    print("="*80)

    if 'test_mae' in df.columns and len(df) >= 2:
        baseline_mae = df.iloc[0]['test_mae']
        print(f"\nåŸºçº¿ (Exp-1) MAE: {baseline_mae:.6f}")
        print("\nç›¸å¯¹æå‡:")
        for idx, row in df.iterrows():
            if idx == 0:
                continue
            improvement = (baseline_mae - row['test_mae']) / baseline_mae * 100
            print(f"  {row['Experiment']}: {improvement:+.2f}% (MAE: {row['test_mae']:.6f})")

    elif 'test_accuracy' in df.columns and len(df) >= 2:
        baseline_acc = df.iloc[0]['test_accuracy']
        print(f"\nåŸºçº¿ (Exp-1) Accuracy: {baseline_acc:.4f}")
        print("\nç»å¯¹æå‡:")
        for idx, row in df.iterrows():
            if idx == 0:
                continue
            improvement = (row['test_accuracy'] - baseline_acc) * 100
            print(f"  {row['Experiment']}: {improvement:+.2f}% (Acc: {row['test_accuracy']:.4f})")

    print("\n" + "="*80)

    return df


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='æ±‡æ€»æ¶ˆèå®éªŒç»“æœ')
    parser.add_argument('--ablation_dir', type=str, required=True,
                        help='æ¶ˆèå®éªŒæ ¹ç›®å½•')

    args = parser.parse_args()

    df = summarize_ablation_experiments(args.ablation_dir)

    if df is not None:
        print(f"\nâœ… æ±‡æ€»å®Œæˆï¼å…± {len(df)} ä¸ªå®éªŒ")
        print(f"è¯¦ç»†ç»“æœä¿å­˜åœ¨: {args.ablation_dir}/ablation_summary.csv")
